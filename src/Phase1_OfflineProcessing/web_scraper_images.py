# src/Phase1_OfflineProcessing/web_scraper_images.py

import requests
from bs4 import BeautifulSoup
from pathlib import Path
from urllib.parse import urljoin
import time

class ArduinoDocsScraper:
    def __init__(self):
        self.base_url = "https://docs.arduino.cc"
        self.tutorial_url = "https://docs.arduino.cc/tutorials/uno-rev3/getting-started/"
        self.image_dir = Path("data/raw/scraped_images/official_docs")
        self.image_dir.mkdir(parents=True, exist_ok=True)
    
    def scrape_getting_started_images(self):
        """ÙƒØ´Ø· Ø§Ù„ØµÙˆØ± Ù…Ù† ØµÙØ­Ø© Getting Started"""
        
        try:
            # Ø¬Ù„Ø¨ Ø§Ù„ØµÙØ­Ø©
            response = requests.get(self.tutorial_url, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ±
            images = soup.find_all('img')
            
            print(f"ğŸ” Found {len(images)} images")
            
            for idx, img in enumerate(images):
                try:
                    img_url = img.get('src')
                    img_alt = img.get('alt', f'image_{idx}')
                    
                    # ØªØ­ÙˆÙŠÙ„ URL Ù†Ø³Ø¨ÙŠ Ø¥Ù„Ù‰ Ù…Ø·Ù„Ù‚
                    if img_url:
                        if img_url.startswith('http'):
                            full_url = img_url
                        else:
                            full_url = urljoin(self.base_url, img_url)
                        
                        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
                        self.download_image(full_url, img_alt)
                        time.sleep(0.5)  # ØªØ£Ø®ÙŠØ± Ø¨ÙŠÙ† Ø§Ù„ØªØ­Ù…ÙŠÙ„Ø§Øª
                
                except Exception as e:
                    print(f"âš ï¸ Error with image {idx}: {e}")
        
        except Exception as e:
            print(f"âŒ Failed to scrape: {e}")
    
    def download_image(self, url, filename):
        """ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø©"""
        
        try:
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯
                ext = url.split('.')[-1].split('?')[0]
                if ext not in ['jpg', 'png', 'gif', 'svg']:
                    ext = 'jpg'
                
                # ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
                clean_filename = "".join(c for c in filename if c.isalnum() or c in '-_')
                
                filepath = self.image_dir / f"{clean_filename}.{ext}"
                with open(filepath, 'wb') as f:
                    f.write(response.content)
                
                print(f"âœ… Saved: {filepath}")
        
        except Exception as e:
            print(f"âš ï¸ Download failed: {e}")

# Ø§Ø³ØªØ®Ø¯Ø§Ù…:
scraper = ArduinoDocsScraper()
scraper.scrape_getting_started_images()
